{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UuaNh8RkXQWS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_article_content(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    article_content = soup.find('div', {'class': 'detail__body-text'})\n",
        "    if article_content:\n",
        "        return article_content.get_text().strip()\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "title = []\n",
        "date = []\n",
        "link = []\n",
        "content = []\n",
        "\n",
        "url = 'https://news.detik.com/berita/d-6805149/saksi-ungkap-awal-mula-shane-lukas-selalu-turuti-mario-dandy'\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "container = soup.find_all('h3', {'class': 'media__title'})\n",
        "\n",
        "url = []\n",
        "for item in container:\n",
        "    url.append(item.find('a').get('href'))\n",
        "\n",
        "for i in url:\n",
        "    response = requests.get(i)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    try:\n",
        "        title.append(soup.find('h1', {'class': 'detail__title'}).get_text().replace('\\n        ', ''))\n",
        "    except:\n",
        "        title.append('')\n",
        "    try:\n",
        "        date.append(soup.find('div', {'class': 'detail__date'}).get_text())\n",
        "    except:\n",
        "        date.append('')\n",
        "    try:\n",
        "        link.append(soup.find('link', {'rel': 'amphtml'}).get('href'))\n",
        "    except:\n",
        "        link.append('')\n",
        "    content.append(get_article_content(i))\n",
        "\n",
        "output = {\n",
        "    \"Title\": title,\n",
        "    \"Date\": date,\n",
        "    \"Link\": url,\n",
        "    \"Content\": content\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(output)"
      ],
      "metadata": {
        "id": "ofPjZbgMXhXV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('try.csv',index=False)"
      ],
      "metadata": {
        "id": "E20XSigAXnaz"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}